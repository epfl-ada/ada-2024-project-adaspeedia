---
layout: ../layouts/TextLayout.astro
title: The story
description: 
---
import '../styles/team.css';

In a world where humanity must rebuild from the ashes, games may seem like a trivial pursuit. Yet, in the aftermath of the apocalypse, our mission at the **Applied Digital Anthropology (ADA)** department of the New Age government is anything but trivial. Tasked with restoring the essence of human civilization, we’ve turned to an unexpected cornerstone of human experience: games.

Our team is exploring how machines can simulate human cognition and strategies to help shape the future of this planet. Why games? Because they encapsulate problem-solving, strategic thinking, and creativity — traits essential for humanity’s survival and progress. To this end, we’ve embarked on a case study of [**Wikispeedia**](https://dlab.epfl.ch/wikispeedia/play/), a game that challenges players to navigate Wikipedia’s web of articles from one topic to another using only hyperlinks. Simple, yet deeply revealing of how humans connect concepts, prioritize paths, and think under constraints.

## Meet the Team
<div class="team-container">
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. A. I." />
        <h3>Dr. A. I.</h3>
        <p>Our lead researcher, a brilliant mind in the field of artificial intelligence and human cognition.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. E. M." />
        <h3>Dr. E. M.</h3>
        <p>Our resident expert in game theory and human psychology.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. L. O." />
        <h3>Dr. L. O.</h3>
        <p>Our data scientist, who wrangles the vast amounts of data we collect from Wikispeedia.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://pmd.lt/pp.jpg" />
        <h3>Dr. P. M.</h3>
        <p>Our game designer, who crafts the challenges that players face in Wikispeedia.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. S. T." />
        <h3>Dr. S. T.</h3>
        <p>Our anthropologist, who studies the social dynamics of Wikispeedia players.</p>
    </div>
</div>

Together, we form **ADAspeedia**, a team united in exploring how machines can emulate and evolve human behavior. To discover the team members' individual stories, click [here](/team).

# A Human Blueprint
To recreate human-like behavior, we first need to understand how humans played Wikispeedia. What strategies did they use? Did they wander aimlessly or systematically? How did they balance the exploration of diverse topics with the focused goal of reaching their destination? These questions guided our initial analysis of the human dataset, revealing the intricacies of the paths taken, the cognitive shortcuts employed, and the common hurdles encountered.

For this, we have data extracted from the Previous Age. A team of researchers from EPFL has collected thousands of paths taken by humans, [unified in a single dataset](https://snap.stanford.edu/data/wikispeedia.html).  
We've analyzed it to keep only the essentials :
- **Paths** - The sequence of articles visited by players (id & title of the articles separated by a comma).


# The machine's understanding of the human language

Prior to our study, other methods already existed to compute the semantic distance between two words. Indeed, language models usually use a system of *word embeddings*, which is a specific representation of words and notions. An interesting point with these embeddings is that they can be visualized as high-dimensionnal vectors. They can hence be compared together with simpler comparison tools, such as the euclidean L2 distance.
Previous studies show that the embeddings learned by models usually capture the semantic behind words. For example, as embeddings are vectors, we can add them up together. It turns out that the result of the operation 'Greece' - 'Athens' + 'Paris' yields a very similar vector to the one representing 'France'.
We are now interested in the similarities in distribution between the difference in distances computed on paths played by humans VS our machine, and the difference in distances computed on paths played by humans VS existing human embeddings.

We first used a Bidirectional Encoder Representations from Transformers (BERT) base model. This architecture has proven to be consistantly powerful on multiple natural language processing tasks, specifically those related to semantic understanding. Hence, it seems like the perfect fit for our task.

To study the distribution of differences, we followed the following protocol:

- Compute the distances for the paths played by humans and by our machine.

- Compute the difference of distance for each path in common.

- Extact the pair of articles.

- Compute for each of the pairs the BERT embeddings of each article.

- Based on the embeddings, compute the euclidean distance between two article names.

- Compute the difference with the distances for the paths played by humans


![Distribution of difference between human computed distances and LLM computed distances](/src/components/charts/difference_humans_llm.png)
![Distribution of difference between human computed distances and embeddings euclidean distance](/src/components/charts/difference_humans_euclidean.png)

For the distribution of difference between human computed and machine computed distances, we can see that the distribution of differences between human and LLM computed distances resembles a Laplace distribution, which clearly indicates a strong alignment between human and machine understanding of semantic relationships. Indeed, this is visible because the mean, median and interquartile range are all very close to 0.
However, the distribution is still spreading a bit, suggesting that the machine may deviate a bit more from human understanding. Besides the obvious outliers previously described (English_language), the largest difference in absolute value suggest different priorities when computing the semantic difference. For example, the difference in the human distance for Canada and Japan and the machine distance shows that the machine potentially thinks more abstractly, i.e. these are two countries, hence the concepts are very similar. However, humans may give more importance to other specificities, such as the geographic distance, lack of common history themes, etc...

Now, looking at the distribution of the difference between human computed distances and embeddings, the data looks more Gaussian, with a mean and median around -6. This means that, distances computed by humans paths are usually way lower than the ones computed by humans, showing discrepancy in the understanding of the human language.

Therefore, we can overall conclude that our machine aligns more with humans in the distance computed based on the paths it plays, hence it mimics the human behavior as expected.
