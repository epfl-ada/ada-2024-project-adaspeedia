---
layout: ../layouts/TextLayout.astro
title: The story
description: 
---
import '../styles/team.css';

In a world where humanity must rebuild from the ashes, games may seem like a trivial pursuit. Yet, in the aftermath of the apocalypse, our mission at the **Applied Digital Anthropology (ADA)** department of the New Age government is anything but trivial. Tasked with restoring the essence of human civilization, we’ve turned to an unexpected cornerstone of human experience: games.

Our team is exploring how machines can simulate human cognition and strategies to help shape the future of this planet. Why games? Because they encapsulate problem-solving, strategic thinking, and creativity — traits essential for humanity’s survival and progress. To this end, we’ve embarked on a case study of [**Wikispeedia**](https://dlab.epfl.ch/wikispeedia/play/), a game that challenges players to navigate Wikipedia’s web of articles from one topic to another using only hyperlinks. Simple, yet deeply revealing of how humans connect concepts, prioritize paths, and think under constraints.

## Meet the Team
<div class="team-container">
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. A. I." />
        <h3>Dr. A. I.</h3>
        <p>Our lead researcher, a brilliant mind in the field of artificial intelligence and human cognition.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. E. M." />
        <h3>Dr. E. M.</h3>
        <p>Our resident expert in game theory and human psychology.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. L. O." />
        <h3>Dr. L. O.</h3>
        <p>Our data scientist, who wrangles the vast amounts of data we collect from Wikispeedia.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="/pp/pm.webp" />
        <h3>Dr. P. M.</h3>
        <p>Our game designer, who crafts the challenges that players face in Wikispeedia.</p>
    </div>
    <div class="team-card" style={{ width: '300px' }}>
        <img src="https://via.placeholder.com/150" alt="Dr. S. T." />
        <h3>Dr. S. T.</h3>
        <p>Our anthropologist, who studies the social dynamics of Wikispeedia players.</p>
    </div>
</div>

Together, we form **ADAspeedia**, a team united in exploring how machines can emulate and evolve human behavior. To discover the team members' individual stories, click [here](/team).

# A Human Blueprint
To recreate human-like behavior, we first need to understand how humans played Wikispeedia. What strategies did they use? Did they wander aimlessly or systematically? How did they balance the exploration of diverse topics with the focused goal of reaching their destination? These questions guided our initial analysis of the human dataset, revealing the intricacies of the paths taken, the cognitive shortcuts employed, and the common hurdles encountered.

For this, we have data extracted from the Previous Age. A team of researchers from EPFL has collected thousands of paths taken by humans, [unified in a single dataset](https://snap.stanford.edu/data/wikispeedia.html).  
We've analyzed it to keep only the essentials

### Articles
This is the data containing the name and data contained in each article. In total we have access to 4604 different articles.

### Links
This is the list of outgoing links from a given source article.
![](/charts/wikispeedia_articles_links.png)
On average, articles have around 26 outgoing links, the median being at 19. Half the articles have between 11 and 33 outgoing links. The United States article has the most outgoing links (294), and each article has at least 1 outgoing link. The distribution of the number of links per article is right-skewed.
We can also look at this data the other way around: based on the articles at our disposal, how many incoming links are there per articles? This can give us an idea of how reachable articles are.
![](/charts/wikispeedia_articles_incoming_links.png)
We can note that articles are always reachable within our given set. The median number of incoming links is of 10, while the mean is of 29 incoming links. Some severe outliers, such as the United States article again with 1551 incoming links, skew the distribution to the right.

### Categories
These refer to the classification of each article based on high level concepts they are each related to. In total, 129 categories are available in our dataset. Most articles are linked to one single category, but a few have more:

- **Paths** - The sequence of articles visited by players (id & title of the articles separated by a comma). These can be subdivided in the success paths (Paths finished) and the failure ones (Paths unfinished).

- **Categories** - The classification of each article in different categories based on the more abstract concepts it is related to.


# The digital mind's capabilities: A comparative analysis

A good first indicator of our machine's capabilities is to look at the lengths of the paths completed.
![](/charts/humans_paths_finished_steps.png)
![](/charts/gpt4omni_no_memory_paths_finished_steps.png)
As visible here, the paths created by humans usually tend to be longer, with a maximum of 435, and a median of 6 steps. The median for the paths created by the LLM without memory is of 3 steps with a maximum of 16. Clearly, LLMs tend to complete paths faster than humans, showing that the machine is clearly playing better than humans. However, we can see some obvious outliers in the humans dataset, e.g. a path finished in 435 steps. This may hinder our ability to truly visualize how both distributions are. To correct that, we suggest looking at the value up to the 99th percentile.
![](/charts/gpt4omni_no_memory_humans_98th_percentile_paths_finished_steps.png)

Over here, we can see more clearly how much both distributions are different. The human paths are spreading more towards the right, i.e. they are more lenghier in general.
We can look at specific examples. United_States -> Abraham_Lincoln. A human mind might first think about Abraham Lincoln being President of the United States, and hence take the path United_States -> President_of_the_United_States -> Abraham_Lincoln. Our machine abstracts these unnecessary connections and "sees" that Abraham_Lincoln is directly reacheable from United_States.
As a first indicator, this shows that our machine is able to think more efficiently than humans. It is able to link two notions together in smaller steps, displaying great skills at this game.

Note: You can use our [**Paths browser**](/browser) to compare how both LLM and humans navigated different paths.

Now, we're interested to see if the machine can succeed where humans fail. We therefore took the paths where humans previously failed, i.e. unique pairs of start and goal articles that have never been finished by humans. We ran our machine on these 1396 paths. Overall we get the following distribution of outcomes.

![](/charts/piechart_llm_on_unfinished.png)

"Wrong answer" refers to the machine trying to access a link that is not part of the ones available at a given step, "Dead end" refers to arriving at an article with no outgoing links and "Loop detected" means that the machine is stuck in a loop.
Here, the machine has been able to finish 30% of paths that humans were previously unable to complete. This shows our machine's superiority against the human race. To go even further, we decided to look at the distribution of the lengths on these new completed paths.

![](/charts/llm_finished_vs_unfinished.png)

We clearly see that overall, our machine takes more steps on these paths than on the previous ones, with a median of 5 steps. This shows that these paths requires more raffined thinking, which can explain why humans failed.

As previously mentionned, humans usually adopt a strategy of getting away then homing in, passing through hubs. Let's see if the most visited articles are similar.

![](/charts/most_visited_articles_human.png)
![](/charts/most_visited_articles_llm.png)

Humans seem to focus on various geographical locations more. In contrast, the machine appears more focused on scientific concepts. Still, some articles appear on both, such as United_States. When looking at the connectivity of the Wikipedia article for United States, it reveals 1551 incoming and 294 outgoing links. This mean that the U.S. article is a great hub that can be easily accessible and lead to many useful links. 
The fact that it is less used than the Wikipedia article for "Animal" on the machine side seems surprising. However, this might reveal some implicit bias from the LLM towards the United_States article. It may not want to use that article as it might have been trained to avoid controversial notions and stay on more "neutral" concepts such as science and nature. This can explain why it prefers going through 'Animal' despite that article being 3 times less reacheable and leading to 10 times less articles than 'United_States'.

# The machine's understanding of the human language

Prior to our study, other methods already existed to compute the semantic distance between two words. Indeed, language models usually use a system of *word embeddings*, which is a specific representation of words and notions. An interesting point with these embeddings is that they can be visualized as high-dimensionnal vectors. They can hence be compared together with simpler comparison tools, such as the euclidean L2 distance.
Previous studies show that the embeddings learned by models usually capture the semantic behind words. For example, as embeddings are vectors, we can add them up together. It turns out that the result of the operation 'Greece' - 'Athens' + 'Paris' yields a very similar vector to the one representing 'France'.
We are now interested in the similarities in distribution between the difference in distances computed on paths played by humans VS our machine, and the difference in distances computed on paths played by humans VS existing human embeddings.

We first used a Bidirectional Encoder Representations from Transformers (BERT) base model. This architecture has proven to be consistantly powerful on multiple natural language processing tasks, specifically those related to semantic understanding. Hence, it seems like the perfect fit for our task.

To study the distribution of differences, we followed the following protocol:

- Compute the distances for the paths played by humans and by our machine.

- Compute the difference of distance for each path in common.

- Extact the pair of articles.

- Compute for each of the pairs the BERT embeddings of each article.

- Based on the embeddings, compute the euclidean distance between two article names.

- Compute the difference with the distances for the paths played by humans


![Distribution of difference between human computed distances and LLM computed distances](/charts/difference_humans_llm.png)
![Distribution of difference between human computed distances and embeddings euclidean distance](/charts/difference_humans_euclidean.png)

For the distribution of difference between human computed and machine computed distances, we can see that the distribution of differences between human and LLM computed distances resembles a Laplace distribution, which clearly indicates a strong alignment between human and machine understanding of semantic relationships. Indeed, this is visible because the mean, median and interquartile range are all very close to 0.
However, the distribution is still spreading a bit, suggesting that the machine may deviate a bit more from human understanding. Besides the obvious outliers previously described (English_language), the largest difference in absolute value suggest different priorities when computing the semantic difference. For example, the difference in the human distance for Canada and Japan and the machine distance shows that the machine potentially thinks more abstractly, i.e. these are two countries, hence the concepts are very similar. However, humans may give more importance to other specificities, such as the geographic distance, lack of common history themes, etc...

Now, looking at the distribution of the difference between human computed distances and embeddings, the data looks more Gaussian, with a mean and median around -6. This means that, distances computed by humans paths are usually way lower than the ones computed by humans, showing discrepancy in the understanding of the human language.

Therefore, we can overall conclude that our machine aligns more with humans in the distance computed based on the paths it plays, hence it mimics the human behavior as expected.
